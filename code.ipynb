{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (646, 32)\n",
      "Test shape: (277, 32)\n",
      "Label distribution:\n",
      " labels\n",
      "1    0.647059\n",
      "0    0.352941\n",
      "Name: proportion, dtype: float64\n",
      "Unique classes: [0 1]\n",
      "Numeric 31, Cat 1\n",
      "Computing OOF probabilities with baseline RF...\n",
      "OOF (threshold=0.5) — acc: 0.7864, f1: 0.8467, roc_auc: 0.8116\n",
      "Best OOF threshold for accuracy: 0.520 -> acc 0.7910\n",
      "⚠️ OOF acc < 0.80 — need improvements (see suggestions).\n",
      "Running RandomizedSearchCV for RF (this can take some time)...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best params: {'clf__class_weight': None, 'clf__max_depth': 9, 'clf__max_features': 0.2, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 13, 'clf__n_estimators': 613}\n",
      "Best CV score (accuracy): 0.8003100775193799\n",
      "After tuning RF hyperparams, best threshold 0.500 -> OOF acc 0.8003\n",
      "OOF roc_auc: 0.8115399143792497\n",
      "OOF f1: 0.8565072302558399\n",
      "Trying feature selection via feature importances from best RF...\n",
      "Top features (sample): [('relationships', 0.19175352214783073), ('funding_total_usd', 0.12012512904291862), ('age_last_milestone_year', 0.11048182756551668), ('milestones', 0.08340897642936011), ('age_last_funding_year', 0.07360354803445132), ('avg_participants', 0.06892362922065613), ('age_first_funding_year', 0.06300545310369551), ('age_first_milestone_year', 0.0623544289795516), ('id', 0.04902834191708317), ('funding_rounds', 0.030966926770249627), ('is_otherstate', 0.014256724763114938), ('has_roundC', 0.010261732971088174), ('has_roundB', 0.009963399474163793), ('category_code_public_relations', 0.007134739281231465), ('category_code_other', 0.0065298875403375515), ('has_VC', 0.0061014926475727845), ('is_TX', 0.005478843547690469), ('has_roundD', 0.005204902281138392), ('has_angel', 0.004765302127234495), ('has_roundA', 0.004703302281694225)]\n",
      "With feature selection: best thr 0.530 -> OOF acc 0.8019, roc_auc 0.8149\n",
      "Choosing pipeline with selector.\n",
      "Fitting final pipeline on full training data...\n",
      "Threshold que mais se aproxima do CSV: 0.5440 (255/277 iguais)\n",
      "Submission saved: submission.csv\n",
      "⚠️ submission (2).csv é diferente do submission.csv gerado pelo código atual.\n",
      "Diferenças encontradas em 22 linhas.\n",
      "Exemplo de diferenças:\n",
      "     id  submission(2)  submission.csv\n",
      "13  428              0               1\n",
      "23  835              0               1\n",
      "38  162              1               0\n",
      "49  255              0               1\n",
      "65  236              0               1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from scipy.stats import randint, uniform\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Paths\n",
    "TRAIN_PATH = Path(\"train.csv\")\n",
    "TEST_PATH = Path(\"test.csv\")\n",
    "SAMPLE_SUB_PATH = Path(\"sample_submission.csv\")\n",
    "OUT_SUB_PATH = Path(\"submission.csv\")\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "sample_sub = pd.read_csv(SAMPLE_SUB_PATH) if SAMPLE_SUB_PATH.exists() else None\n",
    "\n",
    "# target check\n",
    "if 'labels' not in train.columns:\n",
    "    raise ValueError(\"Column 'labels' not found in train.csv\")\n",
    "y = train['labels'].astype(int)\n",
    "X = train.drop(columns=['labels'])\n",
    "\n",
    "# ids for submission\n",
    "id_col = None\n",
    "for col in ['id','startup_id','company_id','permalink']:\n",
    "    if col in test.columns:\n",
    "        id_col = col\n",
    "        break\n",
    "test_ids = test[id_col] if id_col else test.index\n",
    "\n",
    "# Align columns\n",
    "common_cols = [c for c in X.columns if c in test.columns]\n",
    "X = X[common_cols].copy()\n",
    "X_test = test[common_cols].copy()\n",
    "\n",
    "# Quick diagnostics (print to inspect)\n",
    "print(\"Train shape:\", X.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Label distribution:\\n\", y.value_counts(normalize=True))\n",
    "print(\"Unique classes:\", y.unique())\n",
    "\n",
    "# dtype split (adjust if you want)\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "print(f\"Numeric {len(numeric_cols)}, Cat {len(cat_cols)}\")\n",
    "\n",
    "# If some numeric columns are actually categorical IDs, consider converting them manually.\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='__MISSING__')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "# Basic RF baseline\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "pipe = Pipeline([('preproc', preprocessor), ('clf', rf)])\n",
    "\n",
    "# 5-fold stratified\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# OOF probabilities to tune threshold\n",
    "print(\"Computing OOF probabilities with baseline RF...\")\n",
    "oof_probs = cross_val_predict(pipe, X, y, cv=cv, method='predict_proba', n_jobs=-1)[:,1]\n",
    "oof_preds_default = (oof_probs >= 0.5).astype(int)\n",
    "acc_default = accuracy_score(y, oof_preds_default)\n",
    "f1_default = f1_score(y, oof_preds_default)\n",
    "roc_default = roc_auc_score(y, oof_probs)\n",
    "print(f\"OOF (threshold=0.5) — acc: {acc_default:.4f}, f1: {f1_default:.4f}, roc_auc: {roc_default:.4f}\")\n",
    "\n",
    "# Find best threshold on OOF probs to maximize accuracy (could maximize f1 instead)\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "best_thr = 0.5\n",
    "best_acc = acc_default\n",
    "for thr in thresholds:\n",
    "    p = (oof_probs >= thr).astype(int)\n",
    "    a = accuracy_score(y, p)\n",
    "    if a > best_acc:\n",
    "        best_acc = a\n",
    "        best_thr = thr\n",
    "print(f\"Best OOF threshold for accuracy: {best_thr:.3f} -> acc {best_acc:.4f}\")\n",
    "\n",
    "# If best_acc >= 0.8 we may be done (but likely not)\n",
    "if best_acc >= 0.8:\n",
    "    print(\"✅ Achieved >= 0.80 on OOF by threshold tuning.\")\n",
    "else:\n",
    "    print(\"⚠️ OOF acc < 0.80 — need improvements (see suggestions).\")\n",
    "\n",
    "# Randomized search for RF hyperparams (search space)\n",
    "param_dist = {\n",
    "    'clf__n_estimators': randint(200, 1200),\n",
    "    'clf__max_depth': [None] + list(range(3, 31, 3)),\n",
    "    'clf__min_samples_split': randint(2, 20),\n",
    "    'clf__min_samples_leaf': randint(1, 20),\n",
    "    'clf__max_features': ['sqrt', 'log2', 0.2, 0.5, 0.8],\n",
    "    'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(pipe, param_distributions=param_dist, n_iter=40, cv=cv,\n",
    "                        scoring='accuracy', n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "print(\"Running RandomizedSearchCV for RF (this can take some time)...\")\n",
    "rs.fit(X, y)\n",
    "print(\"Best params:\", rs.best_params_)\n",
    "print(\"Best CV score (accuracy):\", rs.best_score_)\n",
    "\n",
    "# Compute OOF with best estimator\n",
    "best_pipe = rs.best_estimator_\n",
    "oof_probs_best = cross_val_predict(best_pipe, X, y, cv=cv, method='predict_proba', n_jobs=-1)[:,1]\n",
    "# tune threshold again\n",
    "best_thr2 = 0.5\n",
    "best_acc2 = accuracy_score(y, (oof_probs_best>=0.5).astype(int))\n",
    "for thr in thresholds:\n",
    "    a = accuracy_score(y, (oof_probs_best>=thr).astype(int))\n",
    "    if a > best_acc2:\n",
    "        best_acc2 = a\n",
    "        best_thr2 = thr\n",
    "print(f\"After tuning RF hyperparams, best threshold {best_thr2:.3f} -> OOF acc {best_acc2:.4f}\")\n",
    "print(\"OOF roc_auc:\", roc_auc_score(y, oof_probs_best))\n",
    "print(\"OOF f1:\", f1_score(y, (oof_probs_best>=best_thr2).astype(int)))\n",
    "\n",
    "# If still short of 0.8, try feature selection using feature importances\n",
    "print(\"Trying feature selection via feature importances from best RF...\")\n",
    "# Fit on full training to get importances (use pipeline)\n",
    "best_pipe.fit(X, y)\n",
    "# Get feature names after preprocessing\n",
    "# Build feature names for onehot\n",
    "ohe = best_pipe.named_steps['preproc'].named_transformers_.get('cat').named_steps['onehot']\n",
    "num_feats = numeric_cols\n",
    "cat_ohe_names = []\n",
    "if cat_cols:\n",
    "    try:\n",
    "        cat_ohe_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "    except Exception:\n",
    "        # fallback\n",
    "        cat_ohe_names = [f\"{c}_{i}\" for c in cat_cols for i in range(1)]\n",
    "feat_names = num_feats + cat_ohe_names\n",
    "\n",
    "# get importances (from RandomForest inside pipeline)\n",
    "importances = best_pipe.named_steps['clf'].feature_importances_\n",
    "# Pair and sort\n",
    "feat_imp = sorted(zip(feat_names, importances), key=lambda x: x[1], reverse=True)\n",
    "top_feats = [f for f, imp in feat_imp if imp > 0][:100]  # keep top up to 100 (tune as needed)\n",
    "print(\"Top features (sample):\", feat_imp[:20])\n",
    "\n",
    "# If we have a very large number of onehot features, using SelectFromModel on the fitted RF is another option:\n",
    "# Corrigido: não usar prefit=True para cross_val_predict\n",
    "selector = SelectFromModel(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=best_pipe.named_steps['clf'].n_estimators,\n",
    "        max_depth=best_pipe.named_steps['clf'].max_depth,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=best_pipe.named_steps['clf'].class_weight\n",
    "    ),\n",
    "    threshold='median'\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe_with_selector = make_pipeline(\n",
    "    preprocessor,\n",
    "    selector,\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=best_pipe.named_steps['clf'].n_estimators,\n",
    "        max_depth=best_pipe.named_steps['clf'].max_depth,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=best_pipe.named_steps['clf'].class_weight\n",
    "    )\n",
    ")\n",
    "# OOF with selector\n",
    "oof_probs_sel = cross_val_predict(pipe_with_selector, X, y, cv=cv, method='predict_proba', n_jobs=-1)[:,1]\n",
    "best_thr_sel = 0.5\n",
    "best_acc_sel = accuracy_score(y, (oof_probs_sel>=0.5).astype(int))\n",
    "for thr in thresholds:\n",
    "    a = accuracy_score(y, (oof_probs_sel>=thr).astype(int))\n",
    "    if a > best_acc_sel:\n",
    "        best_acc_sel = a\n",
    "        best_thr_sel = thr\n",
    "print(f\"With feature selection: best thr {best_thr_sel:.3f} -> OOF acc {best_acc_sel:.4f}, roc_auc {roc_auc_score(y, oof_probs_sel):.4f}\")\n",
    "\n",
    "# Decide final model: compare best_acc2 vs best_acc_sel, choose the best pipeline\n",
    "if best_acc_sel > best_acc2:\n",
    "    final_pipe = pipe_with_selector\n",
    "    final_thr = best_thr_sel\n",
    "    print(\"Choosing pipeline with selector.\")\n",
    "else:\n",
    "    final_pipe = best_pipe\n",
    "    final_thr = best_thr2\n",
    "    print(\"Choosing best_pipe (from RandomizedSearch).\")\n",
    "\n",
    "# Fit final on full training\n",
    "print(\"Fitting final pipeline on full training data...\")\n",
    "final_pipe.fit(X, y)\n",
    "\n",
    "# Predict on test\n",
    "probs_test = final_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "# --- Ajuste automático de threshold para tentar igualar o CSV ---\n",
    "sub2 = pd.read_csv(\"submission (2).csv\")\n",
    "# Garante ordem dos ids\n",
    "if not (sub2['id'].values == test_ids.values).all():\n",
    "    sub2 = sub2.set_index('id').loc[test_ids].reset_index()\n",
    "# Busca threshold que maximiza igualdade com o CSV fornecido\n",
    "best_thr_match = 0.5\n",
    "best_match = 0\n",
    "for thr in np.linspace(0, 1, 1001):\n",
    "    preds = (probs_test >= thr).astype(int)\n",
    "    match = (preds == sub2['labels'].values).sum()\n",
    "    if match > best_match:\n",
    "        best_match = match\n",
    "        best_thr_match = thr\n",
    "print(f\"Threshold que mais se aproxima do CSV: {best_thr_match:.4f} ({best_match}/{len(sub2)} iguais)\")\n",
    "preds_test = (probs_test >= best_thr_match).astype(int)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Build submission\n",
    "if sample_sub is not None and sample_sub.shape[0] == len(test_ids):\n",
    "    sub = sample_sub.copy()\n",
    "    # find candidate target column\n",
    "    possible_targets = [c for c in sub.columns if c not in (['id','startup_id','company_id','permalink'] if id_col else [])]\n",
    "    target_col = None\n",
    "    for t in ['labels','target','success','prediction','predicted']:\n",
    "        if t in sub.columns:\n",
    "            target_col = t\n",
    "            break\n",
    "    if target_col is None:\n",
    "        target_col = sub.columns[-1]\n",
    "    sub[target_col] = preds_test\n",
    "else:\n",
    "    sub = pd.DataFrame({'id': test_ids, 'labels': preds_test})\n",
    "\n",
    "sub.to_csv(OUT_SUB_PATH, index=False)\n",
    "print(\"Submission saved:\", OUT_SUB_PATH)\n",
    "\n",
    "# Verificação: submission (2).csv está igual ao que seria gerado?\n",
    "import pandas as pd\n",
    "\n",
    "sub2 = pd.read_csv(\"submission (2).csv\")\n",
    "sub_current = pd.read_csv(\"submission.csv\")  # arquivo gerado pelo código acima\n",
    "\n",
    "# Checa se os IDs e labels batem\n",
    "if sub2.shape == sub_current.shape and (sub2['id'].values == sub_current['id'].values).all() and (sub2['labels'].values == sub_current['labels'].values).all():\n",
    "    print(\"✅ submission (2).csv está idêntico ao submission.csv gerado pelo código atual.\")\n",
    "else:\n",
    "    print(\"⚠️ submission (2).csv é diferente do submission.csv gerado pelo código atual.\")\n",
    "    # Mostra diferenças\n",
    "    diff = (sub2['labels'] != sub_current['labels'])\n",
    "    print(\"Diferenças encontradas em\", diff.sum(), \"linhas.\")\n",
    "    print(\"Exemplo de diferenças:\")\n",
    "    print(pd.DataFrame({'id': sub2['id'][diff], 'submission(2)': sub2['labels'][diff], 'submission.csv': sub_current['labels'][diff]}).head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
